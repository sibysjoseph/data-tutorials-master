{"paragraphs":[{"text":"%md\n\n## Exploring Spark SQL Module\n### with an Airline Dataset\n","user":"anonymous","dateUpdated":"2018-08-07T19:10:06+0000","config":{"tableHide":false,"editorSetting":{"editOnDblClick":true,"language":"markdown"},"editorMode":"ace/mode/markdown","colWidth":12,"editorHide":true,"fontSize":9,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h2>Exploring Spark SQL Module</h2>\n<h3>with an Airline Dataset</h3>\n"}]},"apps":[],"jobName":"paragraph_1533669006573_-1598572543","id":"20160410-003138_1880368561","dateCreated":"2018-08-07T19:10:06+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:154"},{"title":"Introduction","text":"%md\n\nIn this lab you will use Spark SQL via DataFrames API in Part 1 of the lab and SQL API in Part 2 of the lab to explore an Airline Dataset. This is a very interesting dataset that is further explored in other demo notebooks.","user":"anonymous","dateUpdated":"2018-08-07T19:10:06+0000","config":{"editorSetting":{},"editorMode":"ace/mode/markdown","colWidth":12,"editorHide":true,"fontSize":9,"title":true,"results":[{"graph":{"mode":"table","height":217,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>In this lab you will use Spark SQL via DataFrames API in Part 1 of the lab and SQL API in Part 2 of the lab to explore an Airline Dataset. This is a very interesting dataset that is further explored in other demo notebooks.</p>\n"}]},"apps":[],"jobName":"paragraph_1533669006595_-2006283367","id":"20160410-003138_985055475","dateCreated":"2018-08-07T19:10:06+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:155"},{"text":"%md\n### Datasets and DataFrames\n\nThis tutorial relies on your understanding of Datasets and DataFrames, for a breif explanation on what they are navigate to the accompanying [**Hortonworks Tutorial**](https://hortonworks.com/tutorial/learning-spark-sql-with-zeppelin/#datasets-and-dataframes)","user":"anonymous","dateUpdated":"2018-08-07T19:31:46+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":12,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Datasets and DataFrames</h3>\n<p>This tutorial relies on your understanding of Datasets and DataFrames, for a breif explanation on what they are navigate to the accompanying <a href=\"https://hortonworks.com/tutorial/learning-spark-sql-with-zeppelin/#datasets-and-dataframes\"><strong>Hortonworks Tutorial</strong></a></p>\n"}]},"apps":[],"jobName":"paragraph_1533669006600_578172512","id":"20180806-222529_1721680673","dateCreated":"2018-08-07T19:10:06+0000","dateStarted":"2018-08-07T19:31:46+0000","dateFinished":"2018-08-07T19:31:46+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:156"},{"title":"Verify Spark Version (should be 2.x)","text":"%spark2\n\nspark.version","user":"anonymous","dateUpdated":"2018-08-07T19:10:06+0000","config":{"editorSetting":{"editOnDblClick":false,"language":"scala","completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","colWidth":12,"editorHide":false,"fontSize":9,"title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1533669006602_918644902","id":"20160410-003138_631425785","dateCreated":"2018-08-07T19:10:06+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:157"},{"title":"Download CSV flight data file ","text":"%sh\n\n# You will now download a subset of 2008 flights (only 100k lines)\n# The full dataset may be found here: http://stat-computing.org/dataexpo/2009/the-data.html\n\nwget https://raw.githubusercontent.com/hortonworks/data-tutorials/master/tutorials/hdp/learning-spark-sql-with-zeppelin/assets/flights.csv -O /tmp/flights.csv\necho \"Downloaded!\"","user":"anonymous","dateUpdated":"2018-08-07T19:10:06+0000","config":{"tableHide":false,"editorSetting":{"editOnDblClick":false,"language":"sh","completionSupport":false},"editorMode":"ace/mode/sh","colWidth":12,"editorHide":false,"fontSize":9,"title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1533669006606_-2026489808","id":"20160410-003138_1540125404","dateCreated":"2018-08-07T19:10:06+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:158"},{"title":"Preview Downloaded File","text":"%sh\n\ncat /tmp/flights.csv | head","user":"anonymous","dateUpdated":"2018-08-07T19:10:06+0000","config":{"tableHide":false,"editorSetting":{"editOnDblClick":false,"language":"sh","completionSupport":false},"editorMode":"ace/mode/sh","colWidth":12,"editorHide":false,"fontSize":9,"title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1533669006608_286813812","id":"20160410-003138_226044813","dateCreated":"2018-08-07T19:10:06+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:159"},{"title":"Move dataset to HDFS (if supported/available)","text":"%sh\n\n# remove existing copies of dataset from HDFS\nhdfs dfs -rm -r -f /tmp/flights.csv\n\n# put data into HDFS\nhdfs dfs -put /tmp/flights.csv /tmp/","user":"anonymous","dateUpdated":"2018-08-07T19:10:06+0000","config":{"editorSetting":{"editOnDblClick":false,"language":"sh","completionSupport":false},"editorMode":"ace/mode/sh","colWidth":12,"editorHide":false,"fontSize":9,"title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1533669006611_1043086245","id":"20160410-003138_1267267737","dateCreated":"2018-08-07T19:10:06+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:160"},{"title":"Create a DataFrame from CSV file","text":"%spark2\n\n// Create a flights DataFrame from CSV file\nval flights = (spark.read\n              .option(\"header\", \"true\")                              // Use first line as header\n              .option(\"inferSchema\", \"true\")                         // Infer schema\n              .csv(\"/tmp/flights.csv\"))                               // Read data","user":"anonymous","dateUpdated":"2018-08-07T19:10:06+0000","config":{"editorSetting":{"editOnDblClick":false,"language":"scala","completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","colWidth":12,"editorHide":false,"fontSize":9,"title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1533669006613_1390382421","id":"20160410-003138_236600548","dateCreated":"2018-08-07T19:10:06+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:161"},{"title":"Print Schema","text":"%spark2\n\n// Print the schema in a tree format\nflights.printSchema()","user":"anonymous","dateUpdated":"2018-08-07T19:10:06+0000","config":{"editorSetting":{"editOnDblClick":false,"language":"scala","completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","colWidth":12,"editorHide":false,"fontSize":9,"title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1533669006615_-1233520222","id":"20160410-003138_1553179639","dateCreated":"2018-08-07T19:10:06+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:162"},{"text":"%md\n\n## Part 1: Using DataFrame/Dataset API to Analyze the Airline Data\n\nNote: in this lab DataFrame and Dataset API calls will be indistinguishable. Internally, however, flights are represented as DataFrames and delayedFlights as Datasets in the examples below. Follow along on the [Hortonworks Tutorial](https://hortonworks.com/tutorial/learning-spark-sql-with-zeppelin/#using-dataframe-and-dataset-api-to-analyze-airline-data) for the full story.","user":"anonymous","dateUpdated":"2018-08-07T19:28:15+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h2>Part 1: Using DataFrame/Dataset API to Analyze the Airline Data</h2>\n<p>Note: in this lab DataFrame and Dataset API calls will be indistinguishable. Internally, however, flights are represented as DataFrames and delayedFlights as Datasets in the examples below. Follow along on the <a href=\"https://hortonworks.com/tutorial/learning-spark-sql-with-zeppelin/#using-dataframe-and-dataset-api-to-analyze-airline-data\">Hortonworks Tutorial</a> for the full story.</p>\n"}]},"apps":[],"jobName":"paragraph_1533669807721_428194402","id":"20180807-192327_1873511480","dateCreated":"2018-08-07T19:23:27+0000","dateStarted":"2018-08-07T19:28:15+0000","dateFinished":"2018-08-07T19:28:15+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:163"},{"title":"Show a subset of columns","text":"%spark2\n\n// Show a subset of columns with \"select\"\nflights.select(\"UniqueCarrier\", \"FlightNum\", \"DepDelay\", \"ArrDelay\", \"Distance\").show()","user":"anonymous","dateUpdated":"2018-08-07T19:10:06+0000","config":{"editorSetting":{"editOnDblClick":false,"language":"scala","completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","colWidth":12,"editorHide":false,"fontSize":9,"title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1533669006619_796619536","id":"20160410-003138_1188332400","dateCreated":"2018-08-07T19:10:06+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:164"},{"title":"Apply a filter to find flights delayed more than 15 min","text":"%spark2\n\n// Create a Dataset containing flights with delayed departure by more than 15 min using \"filter\"\nval delayedFlights = (flights\n                        .select(\"UniqueCarrier\", \"DepDelay\")\n                        .filter($\"DepDelay\" > 15))\n                        \ndelayedFlights.show()","user":"anonymous","dateUpdated":"2018-08-07T19:10:06+0000","config":{"editorSetting":{"editOnDblClick":false,"language":"scala","completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","colWidth":12,"editorHide":false,"fontSize":9,"title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1533669006621_-530511550","id":"20160410-003138_704729700","dateCreated":"2018-08-07T19:10:06+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:165"},{"title":"Display percentage of delayed flights","text":"%spark2\n\nval numTotalFlights = flights.count()\nval numDelayedFlights = delayedFlights.count()\n\n// Print total number of delayed flights\nprintln(\"Percentage of Delayed Flights: \" + (numDelayedFlights.toFloat/numTotalFlights*100) + \"%\")","user":"anonymous","dateUpdated":"2018-08-07T19:10:06+0000","config":{"editorSetting":{"editOnDblClick":false,"language":"scala","completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","colWidth":12,"editorHide":false,"fontSize":9,"title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1533669006622_-2025186430","id":"20160410-003138_1019754695","dateCreated":"2018-08-07T19:10:06+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:166"},{"text":"%md\n\nWe can also create a user defined function (UDF) to determine delays.","user":"anonymous","dateUpdated":"2018-08-07T19:10:06+0000","config":{"editorSetting":{},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"fontSize":9,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>We can also create a user defined function (UDF) to determine delays.</p>\n"}]},"apps":[],"jobName":"paragraph_1533669006624_1228631813","id":"20161017-203635_1855560775","dateCreated":"2018-08-07T19:10:06+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:167"},{"title":" Create a UDF to determine delays","text":"%spark2\n\nimport org.apache.spark.sql.functions.udf\n\n// Define a UDF to find delayed flights\n\n// Assume:\n//  if ArrDelay is not available then Delayed = False\n//  if ArrDelay > 15 min then Delayed = True else False\n\nval isDelayedUDF = udf((time: String) => if (time == \"NA\") 0 else if (time.toInt > 15) 1 else 0)","user":"anonymous","dateUpdated":"2018-08-07T19:10:06+0000","config":{"editorSetting":{"editOnDblClick":false,"language":"scala","completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1533669006627_1705968038","id":"20161017-203017_1781904338","dateCreated":"2018-08-07T19:10:06+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:168"},{"title":"Create a new DataFrame with IsDelayed column","text":"%spark2\n\nval flightsWithDelays = flights.select($\"Year\", $\"Month\", $\"DayofMonth\", $\"UniqueCarrier\", $\"FlightNum\", $\"DepDelay\", \n                    isDelayedUDF($\"DepDelay\").alias(\"IsDelayed\"))\n                    \nflightsWithDelays.show(5)","user":"anonymous","dateUpdated":"2018-08-07T19:10:06+0000","config":{"editorSetting":{"editOnDblClick":false,"language":"scala","completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1533669006630_585962540","id":"20161017-203358_1309594443","dateCreated":"2018-08-07T19:10:06+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:169"},{"text":"%md\n\n\nNote that now we have a new table with a column that indicates whether a flight is delayed or not. This will allow us to calculate percentage of delayed flights in one pass.","user":"anonymous","dateUpdated":"2018-08-07T19:10:06+0000","config":{"tableHide":false,"editorSetting":{"editOnDblClick":true,"language":"markdown"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"fontSize":9,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>Note that now we have a new table with a column that indicates whether a flight is delayed or not. This will allow us to calculate percentage of delayed flights in one pass.</p>\n"}]},"apps":[],"jobName":"paragraph_1533669006632_-114989668","id":"20161017-205652_1397194952","dateCreated":"2018-08-07T19:10:06+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:170"},{"title":"Calculate percentage of delayed flights using flightsWithDelays DataFrame","text":"%spark2\n\nflightsWithDelays.agg((sum(\"IsDelayed\") * 100 / count(\"DepDelay\")).alias(\"Percentage of Delayed Flights\")).show()","user":"anonymous","dateUpdated":"2018-08-07T19:10:06+0000","config":{"editorSetting":{"editOnDblClick":false,"language":"scala","completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","editorHide":false,"fontSize":9,"title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1533669006635_-144498854","id":"20161017-205750_819957102","dateCreated":"2018-08-07T19:10:06+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:171"},{"text":"%md\n\nAs you can see above, this is a very clean way of displaying a percentage of delayed flights. UDFs are useful in creating additional functions that are commonly used.\n\nNow let's explore our flights a bit more and find some averages.","user":"anonymous","dateUpdated":"2018-08-07T19:10:06+0000","config":{"editorSetting":{},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"fontSize":9,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>As you can see above, this is a very clean way of displaying a percentage of delayed flights. UDFs are useful in creating additional functions that are commonly used.</p>\n<p>Now let's explore our flights a bit more and find some averages.</p>\n"}]},"apps":[],"jobName":"paragraph_1533669006637_-1731017543","id":"20161017-205919_1405069576","dateCreated":"2018-08-07T19:10:06+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:172"},{"title":"Find Avg Taxi-in","text":"%spark2\n\n(flights.select(\"Origin\", \"Dest\", \"TaxiIn\")\n        .groupBy(\"Origin\", \"Dest\")\n        .agg(avg(\"TaxiIn\")\n        .alias(\"AvgTaxiIn\"))\n        .orderBy(desc(\"AvgTaxiIn\"))\n        .show(10))","user":"anonymous","dateUpdated":"2018-08-07T19:10:06+0000","config":{"editorSetting":{"editOnDblClick":false,"language":"scala","completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","colWidth":6,"editorHide":false,"fontSize":9,"title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1533669006641_450465027","id":"20160410-003138_1488719873","dateCreated":"2018-08-07T19:10:06+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:173"},{"title":"Find Avg Taxi-out","text":"%spark2\n\n(flights.select(\"Origin\", \"Dest\", \"TaxiOut\")\n        .groupBy(\"Origin\", \"Dest\")\n        .agg(avg(\"TaxiOut\")\n        .alias(\"AvgTaxiOut\"))\n        .orderBy(desc(\"AvgTaxiOut\"))\n        .show(10))","user":"anonymous","dateUpdated":"2018-08-07T19:10:06+0000","config":{"editorSetting":{"editOnDblClick":false,"language":"scala","completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","colWidth":6,"editorHide":false,"fontSize":9,"title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1533669006644_-25052345","id":"20160410-003138_840324935","dateCreated":"2018-08-07T19:10:06+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:174"},{"text":"%md\n### Part 2: Using SQL API to Analyze the Airline Data","user":"anonymous","dateUpdated":"2018-08-07T19:10:06+0000","config":{"editorSetting":{},"editorMode":"ace/mode/markdown","colWidth":12,"editorHide":true,"fontSize":9,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Part 2: Using SQL API to Analyze the Airline Data</h3>\n"}]},"apps":[],"jobName":"paragraph_1533669006646_218427617","id":"20160410-003138_582934314","dateCreated":"2018-08-07T19:10:06+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:175"},{"text":"%md\n## Part 2: Using SQL API to Analyze the Airline Data\n\nIn this section we will learn how to use Zeppelin's powerful visualization tools to get a btter understanding of our SQL results. More information back at the [Hortonworks Tutorial](https://hortonworks.com/tutorial/learning-spark-sql-with-zeppelin/#using-sql-api-to-analyze-the-airline-data)","user":"anonymous","dateUpdated":"2018-08-07T19:27:55+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h2>Part 2: Using SQL API to Analyze the Airline Data</h2>\n<p>In this section we will learn how to use Zeppelin's powerful visualization tools to get a btter understanding of our SQL results. More information back at the <a href=\"https://hortonworks.com/tutorial/learning-spark-sql-with-zeppelin/#using-sql-api-to-analyze-the-airline-data\">Hortonworks Tutorial</a></p>\n"}]},"apps":[],"jobName":"paragraph_1533669960059_253631935","id":"20180807-192600_1275134162","dateCreated":"2018-08-07T19:26:00+0000","dateStarted":"2018-08-07T19:27:55+0000","dateFinished":"2018-08-07T19:27:55+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:176"},{"title":"Is there a more interactive way to display query results?","text":"%md\n\nAs you can see, the data displayed in Part 1 of this notebook isn't too interactive. To have a more dynamic experience, let's create a temporary (in-memory) view that we can query against and interact with the resulting data in a table or graph format. The temporary view will allow us to execute SQL queries against it.\n\nNote that the temporary view will reside in memory as long as the Spark session is alive.","user":"anonymous","dateUpdated":"2018-08-07T19:10:06+0000","config":{"editorSetting":{},"editorMode":"ace/mode/markdown","colWidth":12,"editorHide":true,"fontSize":9,"title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>As you can see, the data displayed in Part 1 of this notebook isn't too interactive. To have a more dynamic experience, let's create a temporary (in-memory) view that we can query against and interact with the resulting data in a table or graph format. The temporary view will allow us to execute SQL queries against it.</p>\n<p>Note that the temporary view will reside in memory as long as the Spark session is alive.</p>\n"}]},"apps":[],"jobName":"paragraph_1533669006649_1622374429","id":"20160410-003138_556617784","dateCreated":"2018-08-07T19:10:06+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:177"},{"title":"Register a Temporary View","text":"%spark2\n\n// Convert flights DataFrame to a temporary view\nflights.createOrReplaceTempView(\"flightsView\")","user":"anonymous","dateUpdated":"2018-08-07T19:10:06+0000","config":{"editorSetting":{"editOnDblClick":false,"language":"scala","completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","colWidth":12,"editorHide":false,"fontSize":9,"title":true,"results":[],"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1533669006652_668180994","id":"20160410-003138_636329356","dateCreated":"2018-08-07T19:10:06+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:178"},{"title":"Preview Data in an interactive table format","text":"%spark2.sql\n\nSELECT * FROM flightsView LIMIT 20","user":"anonymous","dateUpdated":"2018-08-07T19:10:06+0000","config":{"editorSetting":{"editOnDblClick":false,"language":"sql","completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql","colWidth":12,"editorHide":false,"fontSize":9,"title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[{"name":"Year","index":0,"aggr":"sum"}],"values":[{"name":"Month","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"Year","index":0,"aggr":"sum"},"yAxis":{"name":"Month","index":1,"aggr":"sum"}},"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"Year":"string","Month":"string","DayofMonth":"string","DayOfWeek":"string","DepTime":"string","CRSDepTime":"string","ArrTime":"string","CRSArrTime":"string","UniqueCarrier":"string","FlightNum":"string","TailNum":"string","ActualElapsedTime":"string","CRSElapsedTime":"string","AirTime":"string","ArrDelay":"string","DepDelay":"string","Origin":"string","Dest":"string","Distance":"string","TaxiIn":"string","TaxiOut":"string","Cancelled":"string","CancellationCode":"string","Diverted":"string","CarrierDelay":"string","WeatherDelay":"string","NASDelay":"string","SecurityDelay":"string","LateAircraftDelay":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1533669006654_968052320","id":"20160410-003138_318924232","dateCreated":"2018-08-07T19:10:06+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:179"},{"title":"Register a User Defined Function (UDF)","text":"%spark2\n\n// Register a helper UDF to find delayed flights\n// Note that this is a UDF specific for use with the sparkSession\n\n// Assume:\n//  if ArrDelay is not available then Delayed = False\n//  if ArrDelay > 15 min then Delayed = True else False\n\nspark.udf.register(\"isDelayedUDF\", (time: String) => if (time == \"NA\") 0 else if (time.toInt > 15) 1 else 0)","user":"anonymous","dateUpdated":"2018-08-07T19:10:06+0000","config":{"editorSetting":{"editOnDblClick":false,"language":"scala","completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","colWidth":12,"editorHide":false,"fontSize":9,"title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1533669006656_-595654342","id":"20160410-003138_40384312","dateCreated":"2018-08-07T19:10:06+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:180"},{"title":"Compare Total Number of Delayed Flights by Carrier","text":"%spark2.sql\n--- Compare Total Number of Delayed Flights by Carrier\nSELECT UniqueCarrier, SUM(isDelayedUDF(DepDelay)) AS NumDelays FROM flightsView GROUP BY UniqueCarrier","user":"anonymous","dateUpdated":"2018-08-07T19:10:06+0000","config":{"editorSetting":{"editOnDblClick":false,"language":"sql","completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql","colWidth":6,"editorHide":false,"fontSize":9,"title":true,"results":[{"graph":{"mode":"pieChart","height":296,"optionOpen":false,"keys":[{"name":"UniqueCarrier","index":0,"aggr":"sum"}],"values":[{"name":"NumDelays","index":1,"aggr":"sum"}],"groups":[],"scatter":{"yAxis":{"name":"NumDelays","index":1,"aggr":"sum"}}}}],"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1533669006657_521251933","id":"20160410-003138_134299332","dateCreated":"2018-08-07T19:10:06+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:181"},{"title":"Compare Total Delayed Time (min) by Carrier","text":"%spark2.sql\n--- Compare Total Delayed Time (min) by Carrier\nSELECT UniqueCarrier, SUM(DepDelay) AS TotalTimeDelay FROM flightsView GROUP BY UniqueCarrier","user":"anonymous","dateUpdated":"2018-08-07T19:10:06+0000","config":{"editorSetting":{"editOnDblClick":false,"language":"sql","completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql","colWidth":6,"editorHide":false,"fontSize":9,"title":true,"results":[{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"keys":[{"name":"UniqueCarrier","index":0,"aggr":"sum"}],"values":[{"name":"TotalTimeDelay","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"UniqueCarrier","index":0,"aggr":"sum"},"yAxis":{"name":"TotalTimeDelay","index":1,"aggr":"sum"}},"setting":{"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1533669006660_270416119","id":"20160410-003138_163559927","dateCreated":"2018-08-07T19:10:06+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:182"},{"title":"Find Average Distance Travelled by Carrier","text":"%spark2.sql\n--- Find Average Distance Travelled by Carrier\nSELECT UniqueCarrier, avg(Distance) AS AvgDistanceTraveled FROM flightsView GROUP BY UniqueCarrier ORDER BY AvgDistanceTraveled DESC","user":"anonymous","dateUpdated":"2018-08-07T19:10:06+0000","config":{"editorSetting":{"editOnDblClick":false,"language":"sql","completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql","colWidth":12,"editorHide":false,"fontSize":9,"title":true,"results":[{"graph":{"mode":"pieChart","height":300,"optionOpen":false,"keys":[{"name":"UniqueCarrier","index":0,"aggr":"sum"}],"values":[{"name":"AvgDistanceTraveled","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"UniqueCarrier","index":0,"aggr":"sum"},"yAxis":{"name":"AvgDistanceTraveled","index":1,"aggr":"sum"}}}}],"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1533669006662_-628308501","id":"20160410-003138_172624929","dateCreated":"2018-08-07T19:10:06+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:183"},{"title":"Find Out When Most Flights Get Delayed by Day of Week","text":"%spark2.sql\n\nSELECT DayOfWeek, CASE WHEN isDelayedUDF(DepDelay) = 1 THEN 'delayed' ELSE 'ok' END AS Delay, COUNT(1) AS Count\nFROM flightsView\nGROUP BY DayOfWeek, CASE WHEN isDelayedUDF(DepDelay) = 1 THEN 'delayed' ELSE 'ok' END\nORDER BY DayOfWeek","user":"anonymous","dateUpdated":"2018-08-07T19:10:06+0000","config":{"editorSetting":{"editOnDblClick":false,"language":"sql","completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql","colWidth":12,"editorHide":false,"fontSize":9,"title":true,"results":[{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"keys":[{"name":"DayOfWeek","index":0,"aggr":"sum"}],"values":[{"name":"Count","index":2,"aggr":"sum"}],"groups":[{"name":"Delay","index":1,"aggr":"sum"}],"scatter":{"xAxis":{"name":"DayOfWeek","index":0,"aggr":"sum"},"yAxis":{"name":"Delay","index":1,"aggr":"sum"}},"setting":{"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1533669006663_399704841","id":"20160410-003138_56774606","dateCreated":"2018-08-07T19:10:06+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:184"},{"title":"Find Out When Most Flights Get Delayed by Hour","text":"%spark2.sql\n\nSELECT CAST(CRSDepTime / 100 AS INT) AS Hour, CASE WHEN isDelayedUDF(DepDelay) = 1 THEN 'delayed' ELSE 'ok' END AS Delay, COUNT(1) AS Count\nFROM flightsView\nGROUP BY CAST(CRSDepTime / 100 AS INT), CASE WHEN isDelayedUDF(DepDelay) = 1 THEN 'delayed' ELSE 'ok' END\nORDER BY Hour","user":"anonymous","dateUpdated":"2018-08-07T19:10:06+0000","config":{"editorSetting":{"editOnDblClick":false,"language":"sql","completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/sql","colWidth":12,"editorHide":false,"fontSize":9,"title":true,"results":[{"graph":{"mode":"stackedAreaChart","height":300,"optionOpen":false,"keys":[{"name":"Hour","index":0,"aggr":"sum"}],"values":[{"name":"Count","index":2,"aggr":"sum"}],"groups":[{"name":"Delay","index":1,"aggr":"sum"}],"scatter":{"xAxis":{"name":"Hour","index":0,"aggr":"sum"},"yAxis":{"name":"Delay","index":1,"aggr":"sum"}},"setting":{"stackedAreaChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1533669006665_-482151171","id":"20160410-003138_728063774","dateCreated":"2018-08-07T19:10:06+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:185"},{"text":"%md\n## Putting it all together\n\nIn this section we will preserve our results for future use or for an application in a different usecase. More concepts and explanation of the code can be found back at the [Tutorials page.](https://hortonworks.com/tutorial/learning-spark-sql-with-zeppelin/#putting-it-all-together)","user":"anonymous","dateUpdated":"2018-08-07T19:30:18+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h2>Putting it all together</h2>\n<p>In this section we will preserve our results for future use or for an application in a different usecase. More concepts and explanation of the code can be found back at the <a href=\"https://hortonworks.com/tutorial/learning-spark-sql-with-zeppelin/#putting-it-all-together\">Tutorials page.</a></p>\n"}]},"apps":[],"jobName":"paragraph_1533670105220_-1239552447","id":"20180807-192825_2041839445","dateCreated":"2018-08-07T19:28:25+0000","dateStarted":"2018-08-07T19:30:18+0000","dateFinished":"2018-08-07T19:30:18+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:186"},{"text":"%md\n### Persisting Results and Data","user":"anonymous","dateUpdated":"2018-08-07T19:31:14+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Persisting Results and Data</h3>\n"}]},"apps":[],"jobName":"paragraph_1533670245397_-1730135850","id":"20180807-193045_1241190912","dateCreated":"2018-08-07T19:30:45+0000","dateStarted":"2018-08-07T19:31:14+0000","dateFinished":"2018-08-07T19:31:14+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:187"},{"title":"Save to ORC file","text":"%spark2\n\nimport org.apache.spark.sql.SaveMode\n\n// Save and Overwrite our new DataFrame to an ORC file\nflightsWithDelays.write.format(\"orc\").mode(SaveMode.Overwrite).save(\"flightsWithDelays.orc\")","user":"anonymous","dateUpdated":"2018-08-07T19:10:06+0000","config":{"editorSetting":{"editOnDblClick":false,"language":"scala","completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","colWidth":12,"editorHide":false,"fontSize":9,"title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1533669006670_-1231624417","id":"20160410-003138_985965720","dateCreated":"2018-08-07T19:10:06+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:188"},{"title":"Load back from an ORC file","text":"%spark2\n\n// Load results back from ORC file\nval test = spark.read.format(\"orc\").load(\"flightsWithDelays.orc\")\n\n// Assert both DataFrames of the same size.\n//   Note that if assertion succeeds no warning messages will be printed\nassert (test.count == flightsWithDelays.count, println(\"Assertion Fail: Files are of different sizes.\"))\n\ntest.show(10)","user":"anonymous","dateUpdated":"2018-08-07T19:10:06+0000","config":{"editorSetting":{"editOnDblClick":false,"language":"scala","completionKey":"TAB","completionSupport":true},"editorMode":"ace/mode/scala","colWidth":12,"editorHide":false,"fontSize":9,"title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1533669006672_-822231801","id":"20160410-003138_1142035788","dateCreated":"2018-08-07T19:10:06+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:189"},{"text":"%md\n\nWe can also create permanent tables, instead of temporary views, using `saveAsTable`. The resulting table will still exist even after your Spark program has restarted.","user":"anonymous","dateUpdated":"2018-08-07T19:10:06+0000","config":{"editorSetting":{},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"fontSize":9,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>We can also create permanent tables, instead of temporary views, using <code>saveAsTable</code>. The resulting table will still exist even after your Spark program has restarted.</p>\n"}]},"apps":[],"jobName":"paragraph_1533669006674_-1665260384","id":"20161017-212315_1033823107","dateCreated":"2018-08-07T19:10:06+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:190"},{"title":"Save DataFrame as Permanent Table","text":"%spark2\n\nflightsWithDelays.write.format(\"orc\").mode(SaveMode.Overwrite).saveAsTable(\"flightswithdelaystbl\")","user":"anonymous","dateUpdated":"2018-08-07T19:10:06+0000","config":{"editorSetting":{"editOnDblClick":false,"language":"scala","completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":[],"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1533669006678_2103422490","id":"20161017-212148_1432557096","dateCreated":"2018-08-07T19:10:06+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:191"},{"title":"Show Tables/Views","text":"%spark2.sql\n\nSHOW TABLES\n\n-- Note that flightsWithDelaysTbl is a permanent table instead of a temporary view!","user":"anonymous","dateUpdated":"2018-08-07T19:10:06+0000","config":{"editorSetting":{"editOnDblClick":false,"language":"sql","completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[{"name":"tableName","index":0,"aggr":"sum"}],"values":[{"name":"isTemporary","index":1,"aggr":"sum"}],"groups":[],"scatter":{"xAxis":{"name":"tableName","index":0,"aggr":"sum"},"yAxis":{"name":"isTemporary","index":1,"aggr":"sum"}}}}],"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1533669006680_1548786895","id":"20161017-212228_2044087527","dateCreated":"2018-08-07T19:10:06+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:192"},{"title":"Querying a Permanent Table","text":"%spark2.sql\n\nSELECT COUNT(1) AS Total from flightswithdelaystbl  -- As you can see, there's no difference in querying a temporary view vs a permanent table","user":"anonymous","dateUpdated":"2018-08-07T19:10:06+0000","config":{"editorSetting":{"editOnDblClick":false,"language":"sql","completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[{"name":"Total","index":0,"aggr":"sum"}],"values":[],"groups":[],"scatter":{"xAxis":{"name":"Total","index":0,"aggr":"sum"}}}}],"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1533669006682_-643655316","id":"20161017-212847_790820933","dateCreated":"2018-08-07T19:10:06+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:193"},{"title":"Final Words","text":"%md\n\nThis should get you started working in Scala with DataFrame, Dataset and SQL Spark APIs that are part of the Spark SQL Module. You should now have the basic tools and code samples to start working on your own data sets: from brining in/downloading datasets, to moving them from local storage to HDFS, to transforming datasets into Spark DataFrames/Datasets/temporary views, querying the data, performing basic calcuations, visualizing, and finally persisiting your results. That's a great start!","user":"anonymous","dateUpdated":"2018-08-07T19:10:06+0000","config":{"editorSetting":{},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"fontSize":9,"title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>This should get you started working in Scala with DataFrame, Dataset and SQL Spark APIs that are part of the Spark SQL Module. You should now have the basic tools and code samples to start working on your own data sets: from brining in/downloading datasets, to moving them from local storage to HDFS, to transforming datasets into Spark DataFrames/Datasets/temporary views, querying the data, performing basic calcuations, visualizing, and finally persisiting your results. That's a great start!</p>\n"}]},"apps":[],"jobName":"paragraph_1533669006683_1551501942","id":"20161017-214817_1787337666","dateCreated":"2018-08-07T19:10:06+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:194"},{"title":"Additional Resources","text":"%md\n\nWe hope you've enjoyed this introductory lab. Below are additional resources that you should find useful:\n\n1. [Hortonworks Apache Spark Tutorials](http://hortonworks.com/tutorials/#tuts-developers) are your natural next step where you can explore Spark in more depth.\n2. [Hortonworks Community Connection (HCC)](https://community.hortonworks.com/spaces/85/data-science.html?type=question) is a great resource for questions and answers on Spark, Data Analytics/Science, and many more Big Data topics.\n3. [Hortonworks Apache Spark Docs](https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.6.5/bk_spark-component-guide/content/ch_developing-spark-apps.html) - official Spark documentation.\n4. [Hortonworks Apache Zeppelin Docs](https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.6.5/bk_zeppelin-component-guide/content/ch_using_zeppelin.html) - official Zeppelin documentation.","user":"anonymous","dateUpdated":"2018-08-07T19:10:06+0000","config":{"tableHide":false,"editorSetting":{"editOnDblClick":true,"language":"markdown","completionSupport":false},"editorMode":"ace/mode/markdown","colWidth":10,"editorHide":true,"fontSize":9,"title":true,"results":[{"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}}],"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p>We hope you've enjoyed this introductory lab. Below are additional resources that you should find useful:</p>\n<ol>\n<li><a href=\"http://hortonworks.com/tutorials/#tuts-developers\">Hortonworks Apache Spark Tutorials</a> are your natural next step where you can explore Spark in more depth.</li>\n<li><a href=\"https://community.hortonworks.com/spaces/85/data-science.html?type=question\">Hortonworks Community Connection (HCC)</a> is a great resource for questions and answers on Spark, Data Analytics/Science, and many more Big Data topics.</li>\n<li><a href=\"https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.6.5/bk_spark-component-guide/content/ch_developing-spark-apps.html\">Hortonworks Apache Spark Docs</a> - official Spark documentation.</li>\n<li><a href=\"https://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.6.5/bk_zeppelin-component-guide/content/ch_using_zeppelin.html\">Hortonworks Apache Zeppelin Docs</a> - official Zeppelin documentation.</li>\n</ol>\n"}]},"apps":[],"jobName":"paragraph_1533669006686_1391430640","id":"20160410-003138_2048237853","dateCreated":"2018-08-07T19:10:06+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:195"},{"text":"%md\n[![HCC Community Logo](https://hortonworks.com/wp-content/uploads/2016/03/logo-hcc.png)](https://community.hortonworks.com/)","user":"anonymous","dateUpdated":"2018-08-07T19:18:35+0000","config":{"colWidth":2,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<p><a href=\"https://community.hortonworks.com/\"><img src=\"https://hortonworks.com/wp-content/uploads/2016/03/logo-hcc.png\" alt=\"HCC Community Logo\" /></a></p>\n"}]},"apps":[],"jobName":"paragraph_1533669397125_1363411161","id":"20180807-191637_533126565","dateCreated":"2018-08-07T19:16:37+0000","dateStarted":"2018-08-07T19:18:35+0000","dateFinished":"2018-08-07T19:18:35+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:196"},{"text":"%md\n","user":"anonymous","dateUpdated":"2018-08-07T19:18:35+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/markdown"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1533669515399_1632542703","id":"20180807-191835_559447505","dateCreated":"2018-08-07T19:18:35+0000","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:197"}],"name":"Learning Spark SQL","id":"2DPGSU83U","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"angular:shared_process":[],"sh:shared_process":[],"spark2:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}